{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Cv6gQVrdHt0"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "gVdQJElrdT9-",
        "outputId": "fef67950-fdaf-4707-c46e-e7a03dfc007f"
      },
      "outputs": [],
      "source": [
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asEFnL2Xdhh8"
      },
      "outputs": [],
      "source": [
        "pip install kaggle -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwzOmqcMds7u"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG81sdDndw0u"
      },
      "outputs": [],
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zlE1tn2d3UT"
      },
      "outputs": [],
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj94Kh4alDIY",
        "outputId": "c9d9e319-b9da-403a-9d47-b1ff15964586"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d rm1000/lung-cancer-histopathological-images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XejgeuqZlnB8"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"lung-cancer-histopathological-images.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"lung_cancer_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji-DESwJl28T",
        "outputId": "22d8d64e-680b-4838-c19d-cd32fbfe1306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "adenocarcinoma\tbenign\tsquamous_cell_carcinoma\n"
          ]
        }
      ],
      "source": [
        "!ls lung_cancer_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICxEyUzPmFzQ"
      },
      "outputs": [],
      "source": [
        "# Importações\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_wf5HoqmKij",
        "outputId": "0c09aeba-dd4c-4297-81ae-d237d4fdc9fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# of images in class squamous_cell_carcinoma: 5000\n",
            "# of images in class adenocarcinoma: 5000\n",
            "# of images in class benign: 5000\n"
          ]
        }
      ],
      "source": [
        "root = '/content/lung_cancer_dataset'\n",
        "classes = os.listdir(root)\n",
        "\n",
        "for i in range(3):\n",
        "    print(f\"# of images in class {classes[i]}: {len(os.listdir(root+'/'+classes[i]))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4JrDtrUmPFf"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # Redimensionamento das imagens\n",
        "    transforms.ToTensor(), # Transformação das imagens para tensores\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Normalização das imagens\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrZfk1jEmSVN"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=root, transform=transform)\n",
        "\n",
        "train_size, val_size = int(0.8 * len(dataset)), int(0.2 * len(dataset)) # 80% das imagens vai para treino, enquanto que 20% para teste\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) # shuffle para evitar memorização (overfitting)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx9Eu5I0nHHD",
        "outputId": "7d33ed34-f083-4978-d97e-9c2395cc3088"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "# Definindo o dispositivo (GPU ou CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Carregar o modelo ResNet-50 pré-treinado\n",
        "model_resnet = models.resnet50(pretrained=True)\n",
        "\n",
        "# Substituindo a última camada para classificar 3 classes\n",
        "num_ftrs = model_resnet.fc.in_features\n",
        "model_resnet.fc = nn.Linear(num_ftrs, 3)\n",
        "\n",
        "# Movendo o modelo para o dispositivo\n",
        "model_resnet.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cND281EanSbZ",
        "outputId": "caedd163-8619-45c5-acdd-daa15f850c2b"
      },
      "outputs": [],
      "source": [
        "# Definindo o critério de perda (CrossEntropyLoss) e o otimizador (SGD)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_resnet.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "print(model_resnet)  # Para verificar a arquitetura modificada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDvW8dLanhUI"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=root, transform=transform)\n",
        "\n",
        "train_size, val_size = int(0.8 * len(dataset)), int(0.2 * len(dataset)) # 80% das imagens vai para treino, enquanto que 20% para teste\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) # shuffle para evitar memorização (overfitting)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_m-Oqh6nmrk",
        "outputId": "abaea315-0008-43be-ca2b-2245ce11632f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Loss: 0.13256405617545047\n",
            "Epoch: 2 | Loss: 0.03211761977244169\n",
            "Epoch: 3 | Loss: 0.012328627890984838\n",
            "Epoch: 4 | Loss: 0.009102295946717883\n",
            "Epoch: 5 | Loss: 0.008005544987934021\n",
            "Epoch: 6 | Loss: 0.0037680816483334637\n",
            "Epoch: 7 | Loss: 0.0037519598958121302\n",
            "Epoch: 8 | Loss: 0.002848215024142216\n",
            "Epoch: 9 | Loss: 0.0020174801901642544\n",
            "Epoch: 10 | Loss: 0.003176094412289482\n",
            "Epoch: 11 | Loss: 0.0013405501421754403\n",
            "Epoch: 12 | Loss: 0.001817594485245839\n",
            "Epoch: 13 | Loss: 0.0011172886414278764\n",
            "Epoch: 14 | Loss: 0.0009844741620569646\n",
            "Epoch: 15 | Loss: 0.001070207129935928\n",
            "Epoch: 16 | Loss: 0.0009020925004491195\n",
            "Epoch: 17 | Loss: 0.0014589463844992376\n",
            "Epoch: 18 | Loss: 0.0009329724078124855\n",
            "Epoch: 19 | Loss: 0.0005065910139674087\n",
            "Epoch: 20 | Loss: 0.0006328377929045625\n",
            "Epoch: 21 | Loss: 0.000929600194428834\n",
            "Epoch: 22 | Loss: 0.000488511000234818\n",
            "Epoch: 23 | Loss: 0.0013256147572113454\n",
            "Epoch: 24 | Loss: 0.0006082726490640197\n",
            "Epoch: 25 | Loss: 0.000438292340610739\n",
            "Epoch: 26 | Loss: 0.00043813296486405306\n",
            "Epoch: 27 | Loss: 0.0003338918797841567\n",
            "Epoch: 28 | Loss: 0.000287908083122602\n",
            "Epoch: 29 | Loss: 0.00032127248018999426\n",
            "Epoch: 30 | Loss: 0.00020430102303726016\n",
            "Epoch: 31 | Loss: 0.0002956058744020993\n",
            "Epoch: 32 | Loss: 0.0006370230390033006\n",
            "Epoch: 33 | Loss: 0.0005088350780042674\n",
            "Epoch: 34 | Loss: 0.0009335893196536441\n",
            "Epoch: 35 | Loss: 0.0003178239439621393\n",
            "Epoch: 36 | Loss: 0.0010535454307767699\n",
            "Epoch: 37 | Loss: 0.00042893910513157606\n",
            "Epoch: 38 | Loss: 0.0004544649043721923\n",
            "Epoch: 39 | Loss: 0.00034918102833277466\n",
            "Epoch: 40 | Loss: 0.00039787598416720965\n",
            "Epoch: 41 | Loss: 0.00017461174039999606\n",
            "Epoch: 42 | Loss: 0.0005849489326089194\n",
            "Epoch: 43 | Loss: 0.0002626728076478078\n",
            "Epoch: 44 | Loss: 0.00016590534212021643\n",
            "Epoch: 45 | Loss: 0.0001885219183513982\n",
            "Epoch: 46 | Loss: 0.00013542828023037145\n",
            "Epoch: 47 | Loss: 0.0006729616784705286\n",
            "Epoch: 48 | Loss: 0.0012688037256745398\n",
            "Epoch: 49 | Loss: 0.00038419896533923746\n",
            "Epoch: 50 | Loss: 0.0005238179462606543\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(50):\n",
        "    model_resnet.train()  # Colocar o modelo em modo de treinamento\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Transferir para o dispositivo\n",
        "\n",
        "        optimizer.zero_grad()  # Zerar os gradientes\n",
        "\n",
        "        outputs = model_resnet(inputs)  # Passar as entradas pelo modelo\n",
        "        loss = criterion(outputs, labels)  # Calcular a perda\n",
        "        loss.backward()  # Retropropagar a perda\n",
        "        optimizer.step()  # Atualizar os pesos\n",
        "\n",
        "        running_loss += loss.item()  # Acumular a perda\n",
        "\n",
        "    # Exibir a perda média por época\n",
        "    print(f\"Epoch: {epoch+1} | Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "    # Salvar o modelo treinado após cada época\n",
        "    torch.save(model_resnet.state_dict(), f\"resnet50_epoch{epoch+1}.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "g7sxp787o9p-",
        "outputId": "a35ecb02-a9d8-4f32-e2d0-d288838d1e32"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Colocar o modelo em modo de avaliação\n",
        "model_resnet.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Listas para armazenar as predições e os rótulos reais\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Mover para o dispositivo (GPU/CPU)\n",
        "\n",
        "        # Passar as imagens pelo modelo\n",
        "        outputs = model_resnet(inputs)\n",
        "\n",
        "        # Obter as predições\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "        # Armazenar as predições e os rótulos reais\n",
        "        all_preds.extend(predictions.cpu().numpy())  # Transferir para CPU e converter para numpy\n",
        "        all_labels.extend(labels.cpu().numpy())  # Transferir para CPU e converter para numpy\n",
        "\n",
        "        # Calcular a acurácia\n",
        "        correct += (predictions == labels).sum().item()\n",
        "        total += len(labels)\n",
        "\n",
        "# Calcular a acurácia\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "conf_mat = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "# Visualizar a matriz de confusão\n",
        "class_names = ['adenocarcinoma', 'benign', 'squamous_cell_carcinoma']  # Atualize com seus nomes de classe\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Classe Predita')\n",
        "plt.ylabel('Classe Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eKBNjgP_Zjh"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Definir as transformações para as imagens\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Certifique-se de que a imagem tem o tamanho correto\n",
        "    transforms.ToTensor(),  # Converte a imagem para tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normaliza com os valores típicos para RGB\n",
        "])\n",
        "\n",
        "# Carregar suas três imagens\n",
        "image_paths = ['lungaca1.jpeg', 'lungn1.jpeg', 'lungscc1.jpeg']  # Altere para o caminho das suas imagens\n",
        "images = []\n",
        "\n",
        "for image_path in image_paths:\n",
        "    image = Image.open(image_path).convert(\"RGB\")  # Abra e converta para RGB\n",
        "    images.append(transform(image))  # Aplique a transformação e adicione à lista\n",
        "\n",
        "# Empacotar as imagens em um tensor (batch)\n",
        "images_tensor = torch.stack(images)  # Agora, temos um tensor com shape (3, 3, 128, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCfL26dKG6N7",
        "outputId": "7dda2b14-b485-4203-a732-0fe73a9539e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imagem 1: Classe prevista: adenocarcinoma\n",
            "Probabilidades: tensor([1.0000e+00, 3.1408e-06, 7.8519e-07], device='cuda:0')\n",
            "Imagem 2: Classe prevista: benign\n",
            "Probabilidades: tensor([8.7386e-08, 1.0000e+00, 4.4555e-11], device='cuda:0')\n",
            "Imagem 3: Classe prevista: squamous_cell_carcinoma\n",
            "Probabilidades: tensor([7.1285e-05, 7.2613e-06, 9.9992e-01], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Certifica que o modelo está na GPU, se disponível\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_resnet.to(device)\n",
        "\n",
        "# Coloca o modelo em modo de avaliação\n",
        "model_resnet.eval()\n",
        "\n",
        "# Move o tensor de imagens para o mesmo dispositivo do modelo\n",
        "images_tensor = images_tensor.to(device)\n",
        "\n",
        "# Realizar a predição sem calcular os gradientes\n",
        "with torch.no_grad():\n",
        "    outputs = model_resnet(images_tensor)\n",
        "    probabilities = torch.softmax(outputs, dim=1)\n",
        "    predicted_classes = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "    class_names = ['adenocarcinoma', 'benign', 'squamous_cell_carcinoma']\n",
        "\n",
        "    for i, predicted_class in enumerate(predicted_classes):\n",
        "        print(f\"Imagem {i+1}: Classe prevista: {class_names[predicted_class.item()]}\")\n",
        "        print(f\"Probabilidades: {probabilities[i]}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
